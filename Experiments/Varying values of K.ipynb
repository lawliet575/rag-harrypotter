{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11262558,"sourceType":"datasetVersion","datasetId":7039400},{"sourceId":11266243,"sourceType":"datasetVersion","datasetId":7042259},{"sourceId":11266411,"sourceType":"datasetVersion","datasetId":7042394}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom langchain_community.document_loaders import PyMuPDFLoader\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.schema.document import Document\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers import pipeline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport textwrap\n\nfrom ragas.metrics import faithfulness, answer_relevancy\nfrom ragas.evaluation import evaluate\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-04-04T16:37:36.162981Z","iopub.execute_input":"2025-04-04T16:37:36.163381Z","iopub.status.idle":"2025-04-04T16:37:36.168635Z","shell.execute_reply.started":"2025-04-04T16:37:36.163345Z","shell.execute_reply":"2025-04-04T16:37:36.167777Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Load and split PDF document\nloader = PyMuPDFLoader(\"/kaggle/input/booooook/Harry Potter Book.pdf\")\npages = loader.load_and_split()\nprint(len(pages))","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:36.178463Z","iopub.execute_input":"2025-04-04T16:37:36.178710Z","iopub.status.idle":"2025-04-04T16:37:36.725326Z","shell.execute_reply.started":"2025-04-04T16:37:36.178690Z","shell.execute_reply":"2025-04-04T16:37:36.724366Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"221\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Initialize embedding model\nembedding_model = HuggingFaceEmbeddings(model_name=\"google/flan-t5-small\")\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:36.726486Z","iopub.execute_input":"2025-04-04T16:37:36.726721Z","iopub.status.idle":"2025-04-04T16:37:46.284870Z","shell.execute_reply.started":"2025-04-04T16:37:36.726701Z","shell.execute_reply":"2025-04-04T16:37:46.283757Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,  # Adjust chunk size as needed\n    chunk_overlap=750  # Ensures context continuity\n)\n\n# Apply chunking to pages\nchunks = text_splitter.split_documents(pages)\nlen(chunks)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:46.286399Z","iopub.execute_input":"2025-04-04T16:37:46.286744Z","iopub.status.idle":"2025-04-04T16:37:46.336745Z","shell.execute_reply.started":"2025-04-04T16:37:46.286704Z","shell.execute_reply":"2025-04-04T16:37:46.335810Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"1269"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# Create FAISS vector database\n#vectordb = FAISS.from_documents(pages, embedding_model)\nvectordb = FAISS.from_documents(chunks, embedding_model)\n\n\n# Save FAISS index to disk for later use\nvectordb.save_local(\"faiss_index\")\n\n# Check the number of stored documents\nprint(f\"Number of documents in the vector store: {vectordb.index.ntotal}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:46.338040Z","iopub.execute_input":"2025-04-04T16:37:46.338421Z","iopub.status.idle":"2025-04-04T16:37:54.804987Z","shell.execute_reply.started":"2025-04-04T16:37:46.338385Z","shell.execute_reply":"2025-04-04T16:37:54.804168Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Number of documents in the vector store: 1269\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"x=9","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:37:54.805793Z","iopub.execute_input":"2025-04-04T16:37:54.806016Z","iopub.status.idle":"2025-04-04T16:37:54.809849Z","shell.execute_reply.started":"2025-04-04T16:37:54.805995Z","shell.execute_reply":"2025-04-04T16:37:54.809018Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Query processing\nquestion = \"Who was Hagrid?\"\nretriever = vectordb.as_retriever(search_kwargs={\"k\": x})\ndocs = retriever.get_relevant_documents(question)\n\n# Print results\nfor i, doc in enumerate(docs, x):\n    page_number = doc.metadata.get('page', 'Unknown')\n    print(f\"Document {i} - Page {page_number} - Score: {doc.metadata.get('score', 'N/A')}\")\n    print(doc.page_content[:500])  # Print first 500 characters of each result\n    print(\"-\" * 80)","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:54.810721Z","iopub.execute_input":"2025-04-04T16:37:54.811023Z","iopub.status.idle":"2025-04-04T16:37:54.842291Z","shell.execute_reply.started":"2025-04-04T16:37:54.810993Z","shell.execute_reply":"2025-04-04T16:37:54.841503Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Document 9 - Page 57 - Score: N/A\nGalleons there were to a pound to know that he was holding more \nmoney than he’d had in his whole life – more money than even \nDudley had ever had. \n‘Might as well get yer uniform,’ said Hagrid, nodding towards \nMadam Malkin’s Robes for All Occasions. ‘Listen, Harry would yeh \nmind if I slipped off fer a pick-me-up in the Leaky Cauldron? I \nhate them Gringotts carts.’ He did still look a bit sick, so Harry \nentered Madam Malkin’s shop alone, feeling nervous. \nMadam Malkin was a squat, smiling wi\n--------------------------------------------------------------------------------\nDocument 10 - Page 169 - Score: N/A\nNORBERT  THE  NORWEGIAN  RIDGEBACK \n171 \n \n \nHe looked very pleased with himself, but Hermione didn’t. \n‘Hagrid, you live in a wooden house,’ she said. \nBut Hagrid wasn’t listening. He was humming merrily as he \nstoked the fire. \n* \nSo now they had something else to worry about: what might hap-\npen to Hagrid if anyone found out he was hiding an illegal dragon \nin his hut. \n‘Wonder what it’s like to have a peaceful life,’ Ron sighed, as \nevening after evening they struggled through all the extra \n--------------------------------------------------------------------------------\nDocument 11 - Page 57 - Score: N/A\nway back, it’s best if I keep me mouth shut,’ said Hagrid. \n* \nOne wild cart-ride later they stood blinking in the sunlight out-\nside Gringotts. Harry didn’t know where to run first now that he \nhad a bag full of money. He didn’t have to know how many \nGalleons there were to a pound to know that he was holding more \nmoney than he’d had in his whole life – more money than even \nDudley had ever had. \n‘Might as well get yer uniform,’ said Hagrid, nodding towards \nMadam Malkin’s Robes for All Occasi\n--------------------------------------------------------------------------------\nDocument 12 - Page 159 - Score: N/A\n‘Oh, honestly, don’t you two read? Look – read that, there.’ \nShe pushed the book towards them, and Harry and Ron read: \n \nThe ancient study of alchemy is concerned with \nmaking the Philosopher’s Stone, a legendary \nsubstance with astonishing powers. The Stone \nwill transform any metal into pure gold. It also \nproduces the Elixir of Life, which will make \nthe drinker immortal. \nThere have been many reports of the Philosopher’s \nStone over the centuries, but the only Stone currently \nin existence\n--------------------------------------------------------------------------------\nDocument 13 - Page 103 - Score: N/A\nYet Harry couldn’t help thinking that Hagrid didn’t quite meet \nhis eyes when he said that. \n‘How’s yer brother Charlie?’ Hagrid asked Ron. ‘I liked him a lot \n– great with animals.’ \nHarry wondered if Hagrid had changed the subject on purpose. \nWhile Ron told Hagrid all about Charlie’s work with dragons, \nHarry picked up a piece of paper that was lying on the table under \nthe tea cosy. It was a cutting from the Daily Prophet: \n \nGRINGOTTS BREAK-IN LATEST \nInvestigations continue into the break-\n--------------------------------------------------------------------------------\nDocument 14 - Page 49 - Score: N/A\nmiles under London, see. Deep under the Underground. Yeh’d die \nof hunger tryin’ ter get out, even if yeh did manage ter get yer \nhands on summat.’ \nHarry sat and thought about this while Hagrid read his news-\npaper, the Daily Prophet. Harry had learnt from Uncle Vernon that \npeople liked to be left alone while they did this, but it was very \ndifficult, he’d never had so many questions in his life. \n‘Ministry o’ Magic messin’ things up as usual,’ Hagrid muttered, \nturning the page. \n‘There’s a M\n--------------------------------------------------------------------------------\nDocument 15 - Page 159 - Score: N/A\nignored him. \n‘Nicolas Flamel,’ she whispered dramatically, ‘is the only known \nmaker of the Philosopher’s Stone!’ \nThis didn’t have quite the effect she’d expected. \n‘The what?’ said Harry and Ron. \n‘Oh, honestly, don’t you two read? Look – read that, there.’ \nShe pushed the book towards them, and Harry and Ron read: \n \nThe ancient study of alchemy is concerned with \nmaking the Philosopher’s Stone, a legendary \nsubstance with astonishing powers. The Stone \nwill transform any metal into pure gol\n--------------------------------------------------------------------------------\nDocument 16 - Page 59 - Score: N/A\ndone, my dear,’ and Harry, not sorry for an excuse to stop talking \nto the boy, hopped down from the footstool. \n‘Well, I’ll see you at Hogwarts, I suppose,’ said the drawling boy. \nHarry was rather quiet as he ate the ice-cream Hagrid had \nbought him (chocolate and raspberry with chopped nuts). \n‘What’s up?’ said Hagrid. \n‘Nothing,’ Harry lied. They stopped to buy parchment and \nquills. Harry cheered up a bit when he found a bottle of ink that \nchanged colour as you wrote. When they had left th\n--------------------------------------------------------------------------------\nDocument 17 - Page 64 - Score: N/A\n66 \nHARRY  POTTER \n \n \nback through the Leaky Cauldron, now empty. Harry didn’t speak \nat all as they walked down the road; he didn’t even notice how \nmuch people were gawping at them on the Underground, laden as \nthey were with all their funny-shaped packages, with the sleeping \nsnowy owl on Harry’s lap. Up another escalator, out into \nPaddington station; Harry only realised where they were when \nHagrid tapped him on the shoulder. \n‘Got time fer a bite to eat before yer train leaves,’ he said. \n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\", #device_map='cuda'\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:54.843266Z","iopub.execute_input":"2025-04-04T16:37:54.843588Z","iopub.status.idle":"2025-04-04T16:37:58.926077Z","shell.execute_reply.started":"2025-04-04T16:37:54.843554Z","shell.execute_reply":"2025-04-04T16:37:58.925322Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f0a3e4f1bb34d179ef994559e51be16"}},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"print(model.dtype)\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total Parameters: {total_params / 1e6} million\")\nmemory_footprint = total_params * 2 / (1024 ** 2)  # Convert to MB\nprint(f\"Estimated Memory Footprint: {memory_footprint:.2f} MB\")","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:58.928070Z","iopub.execute_input":"2025-04-04T16:37:58.928330Z","iopub.status.idle":"2025-04-04T16:37:58.935799Z","shell.execute_reply.started":"2025-04-04T16:37:58.928308Z","shell.execute_reply":"2025-04-04T16:37:58.934870Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"torch.bfloat16\nTotal Parameters: 3085.938688 million\nEstimated Memory Footprint: 5885.96 MB\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Create a pipeline\ngenerator = pipeline(\n\"text-generation\",\nmodel=model,\ntokenizer=tokenizer,\nreturn_full_text=False,\nmax_new_tokens=5000,\ndo_sample=False\n)","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:58.936980Z","iopub.execute_input":"2025-04-04T16:37:58.937536Z","iopub.status.idle":"2025-04-04T16:37:59.011191Z","shell.execute_reply.started":"2025-04-04T16:37:58.937497Z","shell.execute_reply":"2025-04-04T16:37:59.010379Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Extract page content and metadata properly\ndef format_response(doc):\n    return f\"Page {doc.metadata.get('page', 'Unknown')}: {doc.page_content.strip()}\"\n\n# Handle cases where fewer than 3 results are returned\nretrieved_responses = [format_response(doc) for doc in docs[:x]]\nwhile len(retrieved_responses) < x:\n    retrieved_responses.append(\"No relevant information.\")  # Fill missing slots\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:59.015399Z","iopub.execute_input":"2025-04-04T16:37:59.015649Z","iopub.status.idle":"2025-04-04T16:37:59.021103Z","shell.execute_reply.started":"2025-04-04T16:37:59.015629Z","shell.execute_reply":"2025-04-04T16:37:59.020150Z"},"trusted":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Construct the RAG prompt\nprompt = f\"\"\"\nYou are an AI assistant tasked with answering questions based on retrieved knowledge.\n\n### **Retrieved Information**:\n{retrieved_responses[0]}\n{retrieved_responses[1]}\n{retrieved_responses[2]}\n{retrieved_responses[3]}\n{retrieved_responses[4]}\n{retrieved_responses[5]}\n{retrieved_responses[6]}\n{retrieved_responses[7]}\n{retrieved_responses[8]}\n\n\n\n\n\n\n\n\n\n### **Question**:\n{question}\n\n### **Instructions**:\n- Integrate the key points from all retrieved responses into a **cohesive, well-structured answer**.\n- If the responses are **contradictory**, mention the different perspectives.\n- If none of the retrieved responses contain relevant information, reply:\n  **\"I couldn't find a good response to your query in the database.\"**\n\"\"\"\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:59.022125Z","iopub.execute_input":"2025-04-04T16:37:59.022502Z","iopub.status.idle":"2025-04-04T16:37:59.033787Z","shell.execute_reply.started":"2025-04-04T16:37:59.022464Z","shell.execute_reply":"2025-04-04T16:37:59.032817Z"},"trusted":true},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Use Qwen2.5 3B with the correct message format\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\n\n# Generate output using the model\noutput = generator(messages)\n\n# Print formatted response\nprint(textwrap.fill(output[0][\"generated_text\"], width=80))\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:37:59.034675Z","iopub.execute_input":"2025-04-04T16:37:59.034960Z","iopub.status.idle":"2025-04-04T16:38:27.385303Z","shell.execute_reply.started":"2025-04-04T16:37:59.034936Z","shell.execute_reply":"2025-04-04T16:38:27.384311Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Based on the information provided in the retrieved pages, Hagrid is a character\nin the Harry Potter series. Here are some key points about Hagrid:  1. **Job and\nResponsibilities**: Hagrid works as a gamekeeper at Hogwarts School of\nWitchcraft and Wizardry. He is responsible for taking care of the school's\nmagical creatures, including the giant squid, the Hungarian Horntail dragon, and\nthe three-headed dog, Fluffy.  2. **Physical Description**: Hagrid is described\nas a large, burly man with a round face and bushy eyebrows. He has a deep voice\nand often wears a large hat.  3. **Background**: Hagrid comes from a working-\nclass background and has a difficult childhood. He is not a pure-blood wizard\nand is often teased for his lack of magical ability compared to other students.\n4. **Relationships**: Hagrid has a close relationship with Harry Potter, having\ntaken him in as a foster child after Harry's parents were killed. He is also\nfriends with Ron Weasley and Hermione Granger.  5. **Character Traits**: Hagrid\nis known for his loyalty, bravery, and sense of humor. Despite his size and\nsometimes clumsy behavior, he is a skilled fighter and protector.  6.\n**Concerns**: In the text, Hagrid expresses concern about keeping his secret\nregarding an illegal dragon in his hut hidden from others, particularly the\nMinistry of Magic.  Given these points, Hagrid is a significant character in the\nHarry Potter series, playing a crucial role in both the story and the world of\nmagic.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Function to get embeddings for a list of texts (documents)\ndef get_embeddings_for_documents(documents, model):\n    # Use embed_documents to get embeddings for a list of documents\n    return model.embed_documents(documents)\n\n# Function to get embedding for a single text (generated text)\ndef get_embedding_for_query(query, model):\n    # Use embed_query to get embedding for a single query\n    return model.embed_query(query)\n\n# Get embeddings for the retrieved documents and the generated text\nretrieved_documents = [doc.page_content for doc in docs[:x]]\nretrieved_embeddings = get_embeddings_for_documents(retrieved_documents, embedding_model)\ngenerated_text_embedding = get_embedding_for_query(output[0][\"generated_text\"], embedding_model)\n\n# Calculate cosine similarity between each retrieved document and the generated text\nsimilarities = []\nfor doc_embedding in retrieved_embeddings:\n    similarity = cosine_similarity([doc_embedding], [generated_text_embedding])\n    similarities.append(similarity[0][0])\n\n# Print out cosine similarity scores for faithfulness and relevancy\nprint(\"Cosine Similarities (Relevancy Scores):\")\nfor i, similarity in enumerate(similarities, 1):\n    print(f\"Document {i}: Similarity = {similarity:.4f}\")\n\n# Calculate the Faithfulness Score\n# Faithfulness Score: This is the maximum cosine similarity between the generated response and any document\nfaithfulness_score = max(similarities)\nprint(f\"\\nFaithfulness Score: {faithfulness_score:.4f}\")\n\n# Calculate the average relevancy score (mean cosine similarity)\naverage_relevancy_score = np.mean(similarities)\nprint(f\"Average Relevancy Score: {average_relevancy_score:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T16:38:27.386154Z","iopub.execute_input":"2025-04-04T16:38:27.386411Z","iopub.status.idle":"2025-04-04T16:38:27.471650Z","shell.execute_reply.started":"2025-04-04T16:38:27.386389Z","shell.execute_reply":"2025-04-04T16:38:27.470830Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Cosine Similarities (Relevancy Scores):\nDocument 1: Similarity = 0.7528\nDocument 2: Similarity = 0.7546\nDocument 3: Similarity = 0.7645\nDocument 4: Similarity = 0.7890\nDocument 5: Similarity = 0.7662\nDocument 6: Similarity = 0.7314\nDocument 7: Similarity = 0.7873\nDocument 8: Similarity = 0.7485\nDocument 9: Similarity = 0.6970\n\nFaithfulness Score: 0.7890\nAverage Relevancy Score: 0.7546\n","output_type":"stream"}],"execution_count":42}]}