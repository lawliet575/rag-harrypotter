{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOR FASTER COMPUTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T11:07:03.375551Z",
     "iopub.status.busy": "2025-04-04T11:07:03.375245Z",
     "iopub.status.idle": "2025-04-04T11:31:18.159135Z",
     "shell.execute_reply": "2025-04-04T11:31:18.153754Z",
     "shell.execute_reply.started": "2025-04-04T11:07:03.375528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.25.5)\n",
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.50)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.22)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (2.11.0a2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (2.29.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain_community) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.2.2)\n",
      "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f06395fc074a62b0165cf431429524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing chunk_size=250, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=250, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=250, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=500, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=500, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=500, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=500, chunk_overlap=300 ===\n",
      "\n",
      "=== Testing chunk_size=750, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=750, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=750, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=750, chunk_overlap=300 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing chunk_size=750, chunk_overlap=500 ===\n",
      "\n",
      "=== Testing chunk_size=1000, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=1000, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=1000, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=1000, chunk_overlap=300 ===\n",
      "\n",
      "=== Testing chunk_size=1000, chunk_overlap=500 ===\n",
      "\n",
      "=== Testing chunk_size=1000, chunk_overlap=750 ===\n",
      "\n",
      "=== Testing chunk_size=1500, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=1500, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=1500, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=1500, chunk_overlap=300 ===\n",
      "\n",
      "=== Testing chunk_size=1500, chunk_overlap=500 ===\n",
      "\n",
      "=== Testing chunk_size=1500, chunk_overlap=750 ===\n",
      "\n",
      "=== Testing chunk_size=1500, chunk_overlap=1000 ===\n",
      "\n",
      "=== Testing chunk_size=2000, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=2000, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=2000, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=2000, chunk_overlap=300 ===\n",
      "\n",
      "=== Testing chunk_size=2000, chunk_overlap=500 ===\n",
      "\n",
      "=== Testing chunk_size=2000, chunk_overlap=750 ===\n",
      "\n",
      "=== Testing chunk_size=2000, chunk_overlap=1000 ===\n",
      "\n",
      "=== Testing chunk_size=2000, chunk_overlap=1500 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=300 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=500 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=750 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=1000 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=1500 ===\n",
      "\n",
      "=== Testing chunk_size=3000, chunk_overlap=2000 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=300 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=500 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=750 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=1000 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=1500 ===\n",
      "\n",
      "=== Testing chunk_size=4000, chunk_overlap=2000 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=50 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=100 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=200 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=300 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=500 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=750 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=1000 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=1500 ===\n",
      "\n",
      "=== Testing chunk_size=5000, chunk_overlap=2000 ===\n",
      "\n",
      "=== Summary of Results ===\n",
      "Chunk Size   Overlap    Faithfulness    Relevancy      \n",
      "250          50         0.6441          0.6348         \n",
      "250          100        0.6016          0.5699         \n",
      "250          200        0.7018          0.645          \n",
      "500          50         0.6804          0.498          \n",
      "500          100        0.7701          0.6653         \n",
      "500          200        0.6948          0.6438         \n",
      "500          300        0.8105          0.73           \n",
      "750          50         0.6455          0.5624         \n",
      "750          100        0.6795          0.5489         \n",
      "750          200        0.6947          0.6476         \n",
      "750          300        0.7479          0.7082         \n",
      "750          500        0.7676          0.7291         \n",
      "1000         50         0.5673          0.4964         \n",
      "1000         100        0.7414          0.6664         \n",
      "1000         200        0.7028          0.6849         \n",
      "1000         300        0.765           0.7159         \n",
      "1000         500        0.7856          0.7683         \n",
      "1000         750        0.8291          0.8032         \n",
      "1500         50         0.8243          0.7019         \n",
      "1500         100        0.7349          0.6675         \n",
      "1500         200        0.7495          0.7071         \n",
      "1500         300        0.7646          0.7393         \n",
      "1500         500        0.7412          0.6983         \n",
      "1500         750        0.7452          0.6873         \n",
      "1500         1000       0.7562          0.7272         \n",
      "2000         50         0.6687          0.5749         \n",
      "2000         100        0.5554          0.4558         \n",
      "2000         200        0.7218          0.6623         \n",
      "2000         300        0.6407          0.6232         \n",
      "2000         500        0.7045          0.6781         \n",
      "2000         750        0.7859          0.7492         \n",
      "2000         1000       0.7539          0.6946         \n",
      "2000         1500       0.7419          0.6998         \n",
      "3000         50         0.8217          0.7691         \n",
      "3000         100        0.8217          0.7691         \n",
      "3000         200        0.8217          0.7691         \n",
      "3000         300        0.8217          0.7691         \n",
      "3000         500        0.8217          0.7691         \n",
      "3000         750        0.8217          0.7691         \n",
      "3000         1000       0.8217          0.7691         \n",
      "3000         1500       0.8217          0.7691         \n",
      "3000         2000       0.8217          0.7691         \n",
      "4000         50         0.8217          0.7691         \n",
      "4000         100        0.8217          0.7691         \n",
      "4000         200        0.8217          0.7691         \n",
      "4000         300        0.8217          0.7691         \n",
      "4000         500        0.8217          0.7691         \n",
      "4000         750        0.8217          0.7691         \n",
      "4000         1000       0.8217          0.7691         \n",
      "4000         1500       0.8217          0.7691         \n",
      "4000         2000       0.8217          0.7691         \n",
      "5000         50         0.8217          0.7691         \n",
      "5000         100        0.8217          0.7691         \n",
      "5000         200        0.8217          0.7691         \n",
      "5000         300        0.8217          0.7691         \n",
      "5000         500        0.8217          0.7691         \n",
      "5000         750        0.8217          0.7691         \n",
      "5000         1000       0.8217          0.7691         \n",
      "5000         1500       0.8217          0.7691         \n",
      "5000         2000       0.8217          0.7691         \n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "!pip install langchain_community\n",
    "!pip install faiss-gpu\n",
    "!pip install faiss-cpu\n",
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings, textwrap\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load document\n",
    "loader = PyMuPDFLoader(\"/kaggle/input/booooook/Harry Potter Book.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# Embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"google/flan-t5-small\")\n",
    "\n",
    "# Language model\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, return_full_text=False, max_new_tokens=5000, do_sample=False)\n",
    "\n",
    "# Embedding utility functions\n",
    "def get_embeddings_for_documents(documents, model):\n",
    "    return model.embed_documents(documents)\n",
    "\n",
    "def get_embedding_for_query(query, model):\n",
    "    return model.embed_query(query)\n",
    "\n",
    "# Chunking & evaluation loop\n",
    "chunk_sizes = [250, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000]\n",
    "chunk_overlaps = [50, 100, 200, 300, 500, 750, 1000,1500,2000]\n",
    "question = \"Who was Hagrid?\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for chunk_size in chunk_sizes:\n",
    "    for chunk_overlap in chunk_overlaps:\n",
    "        if chunk_overlap >= chunk_size:\n",
    "            continue  # Skip invalid combinations\n",
    "        print(f\"\\n=== Testing chunk_size={chunk_size}, chunk_overlap={chunk_overlap} ===\")\n",
    "\n",
    "        # Chunking\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "        # Vector DB\n",
    "        vectordb = FAISS.from_documents(chunks, embedding_model)\n",
    "        retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "        def format_response(doc):\n",
    "            return f\"Page {doc.metadata.get('page', 'Unknown')}: {doc.page_content.strip()}\"\n",
    "\n",
    "        retrieved_responses = [format_response(doc) for doc in docs[:5]]\n",
    "        while len(retrieved_responses) < 5:\n",
    "            retrieved_responses.append(\"No relevant information.\")\n",
    "\n",
    "        # RAG Prompt\n",
    "        prompt = f\"\"\"\n",
    "You are an AI assistant tasked with answering questions based on retrieved knowledge.\n",
    "\n",
    "### **Retrieved Information**:\n",
    "1️⃣ {retrieved_responses[0]}\n",
    "\n",
    "2️⃣ {retrieved_responses[1]}\n",
    "\n",
    "3️⃣ {retrieved_responses[2]}\n",
    "4️⃣ {retrieved_responses[3]}\n",
    "5️⃣ {retrieved_responses[4]}\n",
    "\n",
    "### **Question**:\n",
    "{question}\n",
    "\n",
    "### **Instructions**:\n",
    "- Integrate the key points from all retrieved responses into a **cohesive, well-structured answer**.\n",
    "- If the responses are **contradictory**, mention the different perspectives.\n",
    "- If none of the retrieved responses contain relevant information, reply:\n",
    "  **\"I couldn't find a good response to your query in the database.\"**\n",
    "\"\"\"\n",
    "\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        output = generator(messages)\n",
    "\n",
    "        # Embeddings\n",
    "        retrieved_documents = [doc.page_content for doc in docs[:5]]\n",
    "        retrieved_embeddings = get_embeddings_for_documents(retrieved_documents, embedding_model)\n",
    "        generated_text_embedding = get_embedding_for_query(output[0][\"generated_text\"], embedding_model)\n",
    "\n",
    "        similarities = []\n",
    "        for doc_embedding in retrieved_embeddings:\n",
    "            similarity = cosine_similarity([doc_embedding], [generated_text_embedding])\n",
    "            similarities.append(similarity[0][0])\n",
    "\n",
    "        faithfulness_score = max(similarities)\n",
    "        avg_relevancy_score = np.mean(similarities)\n",
    "\n",
    "        results.append({\n",
    "            \"chunk_size\": chunk_size,\n",
    "            \"chunk_overlap\": chunk_overlap,\n",
    "            \"faithfulness\": round(faithfulness_score, 4),\n",
    "            \"relevancy\": round(avg_relevancy_score, 4)\n",
    "        })\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== Summary of Results ===\")\n",
    "print(f\"{'Chunk Size':<12} {'Overlap':<10} {'Faithfulness':<15} {'Relevancy':<15}\")\n",
    "for r in results:\n",
    "    print(f\"{r['chunk_size']:<12} {r['chunk_overlap']:<10} {r['faithfulness']:<15} {r['relevancy']:<15}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7039400,
     "sourceId": 11262558,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7042259,
     "sourceId": 11266243,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7042394,
     "sourceId": 11266411,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
